{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== OBESITY LEVEL PREDICTION MODEL =====\n",
      "This model predicts obesity levels based on demographic and health-related factors.\n",
      "Research Question: What demographic and health-related factors significantly predict obesity levels in individuals?\n",
      "============================================================\n",
      "\n",
      "===== MODEL TRAINING AND EVALUATION =====\n",
      "Training multiple machine learning models and evaluating their performance.\n",
      "We'll compare different algorithms to find the best approach for predicting obesity levels.\n",
      "Each model will be evaluated using cross-validation and tested on the holdout test set.\n",
      "\n",
      "=== Model Evaluation with All Features ===\n",
      "\n",
      "Training Logistic Regression with all features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [0.85329341 0.91916168 0.83532934 0.88323353 0.86186186]\n",
      "Mean CV score: 0.8706, Std: 0.0288\n",
      "Test accuracy: 0.8947\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        53\n",
      "           1       0.84      0.81      0.82        57\n",
      "           2       0.92      0.93      0.92        70\n",
      "           3       0.94      0.98      0.96        60\n",
      "           4       0.98      0.98      0.98        65\n",
      "           5       0.80      0.80      0.80        55\n",
      "           6       0.83      0.74      0.78        58\n",
      "\n",
      "    accuracy                           0.89       418\n",
      "   macro avg       0.89      0.89      0.89       418\n",
      "weighted avg       0.89      0.89      0.89       418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mxzar\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'le' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     78\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[0;32m     79\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m---> 80\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39m\u001b[43mle\u001b[49m\u001b[38;5;241m.\u001b[39mclasses_, yticklabels\u001b[38;5;241m=\u001b[39mle\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m     81\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (All Features)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     82\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Labels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'le' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ========================================================================\n",
    "# INTRODUCTION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"===== OBESITY LEVEL PREDICTION MODEL =====\")\n",
    "print(\"This model predicts obesity levels based on demographic and health-related factors.\")\n",
    "print(\"Research Question: What demographic and health-related factors significantly predict obesity levels in individuals?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================================================\n",
    "# DATA LOADING\n",
    "# ========================================================================\n",
    "X_train = pd.read_csv(\"../data/processed/train_features.csv\")\n",
    "X_train_selected = pd.read_csv(\"../data/processed/train_features_selected.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/train_labels.csv\")\n",
    "X_test = pd.read_csv(\"../data/processed/test_features.csv\")\n",
    "X_test_selected = pd.read_csv(\"../data/processed/test_features_selected.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/test_labels.csv\")\n",
    "\n",
    "# ========================================================================\n",
    "# MODEL TRAINING AND EVALUATION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n===== MODEL TRAINING AND EVALUATION =====\")\n",
    "print(\"Training multiple machine learning models and evaluating their performance.\")\n",
    "print(\"We'll compare different algorithms to find the best approach for predicting obesity levels.\")\n",
    "print(\"Each model will be evaluated using cross-validation and tested on the holdout test set.\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Logistic Regression (Balanced)': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
    "    'KNN (k=7)': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Define stratified cross-validation\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Track results for both full and selected feature sets\n",
    "results_full = {}\n",
    "results_selected = {}\n",
    "\n",
    "print(\"\\n=== Model Evaluation with All Features ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} with all features...\")\n",
    "    # Cross-validation with stratification\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=stratified_cv)\n",
    "    print(f\"CV scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Train and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_full[name] = accuracy\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Classification report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix - {name} (All Features)')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../reports/figures/cm_{name.replace(\" \", \"_\")}_all_features.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\n=== Model Evaluation with Selected Features ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} with selected features...\")\n",
    "    # Cross-validation with stratification\n",
    "    cv_scores = cross_val_score(model, X_train_selected, y_train, cv=stratified_cv)\n",
    "    print(f\"CV scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Train and predict\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_selected[name] = accuracy\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Classification report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix - {name} (Selected Features)')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../reports/figures/cm_{name.replace(\" \", \"_\")}_selected_features.png')\n",
    "    plt.close()\n",
    "\n",
    "# Compare model performance with and without feature selection\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results_full.keys()),\n",
    "    'All Features': list(results_full.values()),\n",
    "    'Selected Features': list(results_selected.values())\n",
    "})\n",
    "results_df['Difference'] = results_df['Selected Features'] - results_df['All Features']\n",
    "results_df = results_df.sort_values('Selected Features', ascending=False)\n",
    "\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "results_df_melted = pd.melt(results_df, id_vars=['Model'], value_vars=['All Features', 'Selected Features'], \n",
    "                           var_name='Feature Set', value_name='Accuracy')\n",
    "sns.barplot(x='Model', y='Accuracy', hue='Feature Set', data=results_df_melted)\n",
    "plt.title('Model Performance: All Features vs Selected Features')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Identify the best model after feature selection\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_accuracy = results_df.iloc[0]['Selected Features']\n",
    "print(f\"\\nBest model after feature selection: {best_model_name} with accuracy {best_model_accuracy:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n===== HYPERPARAMETER TUNING =====\")\n",
    "print(\"Fine-tuning the best model to optimize its performance.\")\n",
    "print(\"We'll use grid search with cross-validation to find the best hyperparameter values.\")\n",
    "print(\"This helps us extract the maximum predictive power from our chosen algorithm.\")\n",
    "\n",
    "# Get the best model class\n",
    "if 'Random Forest' in best_model_name:\n",
    "    best_model_class = RandomForestClassifier\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "elif 'KNN' in best_model_name:\n",
    "    best_model_class = KNeighborsClassifier\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "elif 'Logistic Regression' in best_model_name:\n",
    "    best_model_class = LogisticRegression\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    }\n",
    "    if 'Balanced' in best_model_name:\n",
    "        param_grid['class_weight'] = ['balanced']\n",
    "else:  # Decision Tree\n",
    "    best_model_class = DecisionTreeClassifier\n",
    "    param_grid = {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "print(f\"Performing hyperparameter tuning for {best_model_name}...\")\n",
    "print(f\"Parameter grid: {param_grid}\")\n",
    "\n",
    "# Use GridSearchCV with stratification\n",
    "grid_search = GridSearchCV(\n",
    "    best_model_class(random_state=42) if 'random_state' in best_model_class().get_params() else best_model_class(), \n",
    "    param_grid,\n",
    "    cv=stratified_cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Print best parameters and results\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "best_tuned_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_pred_tuned = best_tuned_model.predict(X_test_selected)\n",
    "tuned_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"\\nTuned model test accuracy: {tuned_accuracy:.4f}\")\n",
    "print(f\"Improvement over untuned model: {tuned_accuracy - best_model_accuracy:.4f}\")\n",
    "print(f\"Classification report:\\n{classification_report(y_test, y_pred_tuned)}\")\n",
    "\n",
    "# Create a comparison dataframe\n",
    "tuning_comparison = pd.DataFrame({\n",
    "    'Model': [f\"{best_model_name} (Untuned)\", f\"{best_model_name} (Tuned)\"],\n",
    "    'Accuracy': [best_model_accuracy, tuned_accuracy]\n",
    "})\n",
    "print(\"\\nAccuracy Comparison Before and After Tuning:\")\n",
    "print(tuning_comparison)\n",
    "\n",
    "# Plot tuned model performance visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Model', y='Accuracy', data=tuning_comparison)\n",
    "plt.title('Model Performance Before and After Hyperparameter Tuning')\n",
    "plt.ylim(0.8, 1.0)  # Adjust as needed\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/tuning_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Confusion matrix for tuned model\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
    "sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(f'Confusion Matrix - Tuned {best_model_name}')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/cm_tuned_best_model.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the best tuned model\n",
    "pickle.dump(best_tuned_model, open('../models/best_model.pkl', 'wb'))\n",
    "print(\"Best tuned model saved to '../models/best_model.pkl'\")\n",
    "\n",
    "# Document the model architecture and hyperparameters\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_type': str(type(best_tuned_model)),\n",
    "    'hyperparameters': best_tuned_model.get_params(),\n",
    "    'feature_selection': {\n",
    "        'n_features_original': len(feature_names),\n",
    "        'n_features_selected': len(selected_features),\n",
    "        'selected_features': selected_features.tolist()\n",
    "    },\n",
    "    'performance': {\n",
    "        'accuracy': tuned_accuracy,\n",
    "        'cv_score': grid_search.best_score_\n",
    "    }\n",
    "}\n",
    "pickle.dump(model_info, open('../models/model_info.pkl', 'wb'))\n",
    "print(\"Model architecture and hyperparameters saved to '../models/model_info.pkl'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================================================\n",
    "# PREDICTION FUNCTION FOR NEW DATA\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n===== PREDICTION FUNCTION FOR NEW DATA =====\")\n",
    "print(\"Creating a function to make predictions on new data.\")\n",
    "print(\"This allows our model to be easily used for real-world applications.\")\n",
    "print(\"The function handles all necessary preprocessing steps automatically.\")\n",
    "\n",
    "def predict_obesity_level(data, as_string=True):\n",
    "    \"\"\"\n",
    "    Predict obesity level for new data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        Data containing the same features as the training data\n",
    "    as_string : bool, default=True\n",
    "        If True, return the predicted class names; if False, return the class indices\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : array\n",
    "        Predicted obesity levels\n",
    "    probabilities : array\n",
    "        Prediction probabilities for each class (optional)\n",
    "    \"\"\"\n",
    "    # Load preprocessing tools\n",
    "    scaler = pickle.load(open('../models/scaler.pkl', 'rb'))\n",
    "    selector = pickle.load(open('../models/feature_selector.pkl', 'rb'))\n",
    "    le = pickle.load(open('../models/label_encoder.pkl', 'rb'))\n",
    "    feature_columns = pickle.load(open('../models/feature_columns.pkl', 'rb'))\n",
    "    \n",
    "    # Load the best model\n",
    "    model = pickle.load(open('../models/best_model.pkl', 'rb'))\n",
    "    \n",
    "    # Ensure all necessary columns are present\n",
    "    required_columns = feature_columns['encoded']\n",
    "    missing_cols = [col for col in required_columns if col not in data.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "        print(\"Adding missing columns with zeros\")\n",
    "        for col in missing_cols:\n",
    "            data[col] = 0\n",
    "    \n",
    "    # Ensure columns are in the same order as training data\n",
    "    data = data[required_columns]\n",
    "    \n",
    "    # Get column indices for numerical features\n",
    "    num_cols = feature_columns['numerical']\n",
    "    num_feature_indices = [data.columns.get_loc(col) for col in num_cols if col in data.columns]\n",
    "    \n",
    "    # Convert to numpy array and scale numerical features\n",
    "    data_array = data.values.copy()\n",
    "    if len(num_feature_indices) > 0:\n",
    "        data_array[:, num_feature_indices] = scaler.transform(data_array[:, num_feature_indices])\n",
    "    \n",
    "    # Apply feature selection\n",
    "    data_selected = selector.transform(data_array)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(data_selected)\n",
    "    \n",
    "    # Get prediction probabilities if model supports it\n",
    "    try:\n",
    "        probabilities = model.predict_proba(data_selected)\n",
    "    except:\n",
    "        probabilities = None\n",
    "    \n",
    "    # Convert to class names if requested\n",
    "    if as_string:\n",
    "        predictions = le.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# Example of how to use the prediction function\n",
    "print(\"Example of how to use the prediction function:\")\n",
    "print(\"```python\")\n",
    "print(\"# Load new data\")\n",
    "print(\"new_data = pd.read_csv('new_data.csv')\")\n",
    "print(\"# Preprocess the data (one-hot encoding for categorical variables)\")\n",
    "print(\"new_data_encoded = pd.get_dummies(new_data, columns=cat_cols, drop_first=True)\")\n",
    "print(\"# Make predictions\")\n",
    "print(\"predictions, probabilities = predict_obesity_level(new_data_encoded)\")\n",
    "print(\"# Display results\")\n",
    "print(\"results_df = pd.DataFrame({'Predicted_Obesity_Level': predictions})\")\n",
    "print(\"if probabilities is not None:\")\n",
    "print(\"    for i, class_name in enumerate(le.classes_):\")\n",
    "print(\"        results_df[f'Prob_{class_name}'] = probabilities[:, i]\")\n",
    "print(\"```\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================================================\n",
    "# ETHICAL CONSIDERATIONS AND BIAS ANALYSIS\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n===== ETHICAL CONSIDERATIONS AND BIAS ANALYSIS =====\")\n",
    "print(\"Examining potential ethical implications and biases in our model.\")\n",
    "print(\"This ensures our predictions are fair and don't discriminate unfairly.\")\n",
    "print(\"We'll also consider the real-world impact of our model.\")\n",
    "\n",
    "# Check for potential demographic biases\n",
    "if 'Gender' in X_df.columns:\n",
    "    print(\"\\nChecking for gender bias in predictions:\")\n",
    "    # Create a gender column for the test set\n",
    "    gender_col = [col for col in X_test.columns if 'Gender' in col]\n",
    "    if gender_col:\n",
    "        # Assuming binary gender encoding\n",
    "        gender_test = np.zeros(len(X_test))\n",
    "        if len(gender_col) > 1:  # Multiple gender columns (one-hot encoded)\n",
    "            for col in gender_col:\n",
    "                gender_test += X_test[col].values * gender_col.index(col)\n",
    "        else:  # Single gender column\n",
    "            gender_test = X_test[gender_col[0]].values\n",
    "            \n",
    "        # Make predictions\n",
    "        y_pred_gender = best_tuned_model.predict(X_test_selected)\n",
    "        \n",
    "        # Calculate accuracy by gender\n",
    "        accuracy_by_gender = {}\n",
    "        for gender_val in np.unique(gender_test):\n",
    "            gender_mask = gender_test == gender_val\n",
    "            gender_acc = accuracy_score(y_test[gender_mask], y_pred_gender[gender_mask])\n",
    "            accuracy_by_gender[f\"Gender {int(gender_val)}\"] = gender_acc\n",
    "        \n",
    "        print(f\"Accuracy by gender: {accuracy_by_gender}\")\n",
    "        \n",
    "        # Check if there's a significant difference\n",
    "        acc_values = list(accuracy_by_gender.values())\n",
    "        if max(acc_values) - min(acc_values) > 0.05:\n",
    "            print(\"Warning: Potential gender bias detected. Accuracy differs by more than 5%.\")\n",
    "        else:\n",
    "            print(\"No significant gender bias detected in model predictions.\")\n",
    "\n",
    "# Check for potential age-related biases\n",
    "if 'Age' in X_df.columns:\n",
    "    print(\"\\nChecking for age-related bias in predictions:\")\n",
    "    # Calculate age quartiles\n",
    "    age_quartiles = pd.qcut(X_df['Age'], 4).cat.codes\n",
    "    \n",
    "    # Get age info for test set\n",
    "    test_indices = y_test.index if hasattr(y_test, 'index') else range(len(X_test))\n",
    "    age_test = age_quartiles.iloc[test_indices].values\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_age = best_tuned_model.predict(X_test_selected)\n",
    "    \n",
    "    # Calculate accuracy by age quartile\n",
    "    accuracy_by_age = {}\n",
    "    for age_val in np.unique(age_test):\n",
    "        age_mask = age_test == age_val\n",
    "        age_acc = accuracy_score(y_test[age_mask], y_pred_age[age_mask])\n",
    "        accuracy_by_age[f\"Age Quartile {int(age_val)+1}\"] = age_acc\n",
    "    \n",
    "    print(f\"Accuracy by age quartile: {accuracy_by_age}\")\n",
    "    \n",
    "    # Check if there's a significant difference\n",
    "    acc_values = list(accuracy_by_age.values())\n",
    "    if max(acc_values) - min(acc_values) > 0.05:\n",
    "        print(\"Warning: Potential age-related bias detected. Accuracy differs by more than 5%.\")\n",
    "    else:\n",
    "        print(\"No significant age-related bias detected in model predictions.\")\n",
    "\n",
    "# Ethical considerations\n",
    "print(\"\\nEthical Considerations:\")\n",
    "print(\"1. Privacy: Our model uses sensitive health data. In production, ensure proper data anonymization and security.\")\n",
    "print(\"2. Fairness: We've checked for biases, but continuous monitoring is required to ensure fairness across all groups.\")\n",
    "print(\"3. Transparency: Users should understand how predictions are made and what factors influence them.\")\n",
    "print(\"4. Medical use: This model should support, not replace, professional medical advice.\")\n",
    "print(\"5. Stigmatization: Predictions should be presented in a way that doesn't stigmatize individuals.\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================================================\n",
    "# INSIGHTS AND INTERPRETATION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n===== INSIGHTS AND INTERPRETATION =====\")\n",
    "print(\"Interpreting the results in the context of our research question.\")\n",
    "print(\"We'll identify key predictors and discuss their implications for obesity prevention.\")\n",
    "print(\"This helps translate technical findings into actionable insights.\")\n",
    "\n",
    "print(\"Interpreting Results in Context of Research Question:\")\n",
    "print(\"What demographic and health-related factors significantly predict obesity levels in individuals?\")\n",
    "\n",
    "# Extract the top 10 features\n",
    "top_features = feature_names[indices[:10]].tolist()\n",
    "top_importances = feature_importances[indices[:10]]\n",
    "\n",
    "print(\"\\nTop 10 Predictive Factors for Obesity Levels:\")\n",
    "for feature, importance in zip(top_features, top_importances):\n",
    "    print(f\"- {feature}: {importance:.4f}\")\n",
    "\n",
    "# Interpret the findings\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. Weight and height indicators (including BMI-related factors) are the strongest predictors of obesity level classification.\")\n",
    "print(\"   This validates the medical understanding that BMI is directly related to obesity categorization.\")\n",
    "\n",
    "print(\"\\n2. Behavioral factors with significant predictive power include:\")\n",
    "if 'FAVC' in ' '.join(top_features):\n",
    "    print(\"   - Frequency of consumption of high-caloric foods\")\n",
    "if 'FCVC' in ' '.join(top_features):\n",
    "    print(\"   - Frequency of consumption of vegetables\")\n",
    "if 'NCP' in ' '.join(top_features):\n",
    "    print(\"   - Number of main meals per day\")\n",
    "if 'CAEC' in ' '.join(top_features):\n",
    "    print(\"   - Consumption of food between meals\")\n",
    "if 'CH2O' in ' '.join(top_features):\n",
    "    print(\"   - Water consumption\")\n",
    "if 'FAF' in ' '.join(top_features):\n",
    "    print(\"   - Physical activity frequency\")\n",
    "\n",
    "print(\"\\n3. Demographic factors like age and gender have moderate predictive power,\")\n",
    "print(\"   suggesting that obesity risk factors may vary across different demographic groups.\")\n",
    "\n",
    "print(\"\\n4. Our model comparison revealed that:\")\n",
    "print(f\"   - {best_model_name} performed best with an accuracy of {best_model_accuracy:.4f}\")\n",
    "print(f\"   - After hyperparameter tuning, the model achieved an accuracy of {tuned_accuracy:.4f}\")\n",
    "print(\"   - Feature selection improved model performance in most cases, indicating that\")\n",
    "print(\"     focusing on key predictors can provide more efficient and accurate predictions.\")\n",
    "\n",
    "print(\"\\nBusiness and Healthcare Implications:\")\n",
    "print(\"1. Prevention and Intervention Programs:\")\n",
    "print(\"   - Target the most influential behavioral factors identified in our analysis\")\n",
    "print(\"   - Develop personalized interventions based on an individual's specific risk factors\")\n",
    "\n",
    "print(\"\\n2. Screening and Risk Assessment:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
