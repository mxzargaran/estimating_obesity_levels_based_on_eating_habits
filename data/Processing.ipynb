{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
      "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
      "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
      "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
      "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
      "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
      "\n",
      "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
      "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
      "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
      "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
      "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
      "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
      "\n",
      "                  MTRANS           NObeyesdad  \n",
      "0  Public_Transportation        Normal_Weight  \n",
      "1  Public_Transportation        Normal_Weight  \n",
      "2  Public_Transportation        Normal_Weight  \n",
      "3                Walking   Overweight_Level_I  \n",
      "4  Public_Transportation  Overweight_Level_II  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "\n",
    "head = df.head()\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FEATURE TYPES =====\n",
      "Identified 8 categorical columns: ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
      "Identified 8 numerical columns: ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Store the target variable separately before preprocessing\n",
    "y_original = df['NObeyesdad'].copy()\n",
    "\n",
    "# Automatically identify categorical and numerical columns\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove target variable from categorical columns if present\n",
    "if 'NObeyesdad' in cat_cols:\n",
    "    cat_cols.remove('NObeyesdad')\n",
    "\n",
    "# Remove target variable from numerical columns if present\n",
    "if 'NObeyesdad' in num_cols:\n",
    "    num_cols.remove('NObeyesdad')\n",
    "\n",
    "\n",
    "print(f\"\\n===== FEATURE TYPES =====\")\n",
    "print(f\"Identified {len(cat_cols)} categorical columns: {cat_cols}\")\n",
    "print(f\"Identified {len(num_cols)} numerical columns: {num_cols}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "Preparing the data for model training by encoding categorical variables,\n",
    "scaling numerical features, and splitting into training and testing sets.\n",
    "This step ensures our data is in the correct format for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapping: {'Insufficient_Weight': 0, 'Normal_Weight': 1, 'Obesity_Type_I': 2, 'Obesity_Type_II': 3, 'Obesity_Type_III': 4, 'Overweight_Level_I': 5, 'Overweight_Level_II': 6}\n",
      "Label encoder saved to '../models/label_encoder.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Label Encode target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_original)\n",
    "class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(f\"Classes mapping: {class_mapping}\")\n",
    "\n",
    "# Drop the target variable from the dataframe before one-hot encoding\n",
    "X_df = df.drop('NObeyesdad', axis=1)\n",
    "\n",
    "# Save the label encoder for future use\n",
    "pickle.dump(le, open('../models/label_encoder.pkl', 'wb'))\n",
    "print(\"Label encoder saved to '../models/label_encoder.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1669, 16), Test set: (418, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test sets with stratification to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set after preprocessing: (1669, 23)\n",
      "Test set after preprocessing: (418, 23)\n",
      "Preprocessor pipeline saved to '../models/preprocessor.pkl'\n",
      "Feature column names saved to '../models/feature_columns.pkl'\n",
      "{'categorical': ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS'], 'numerical': ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE'], 'encoded': ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'Gender_Male', 'family_history_with_overweight_yes', 'FAVC_yes', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'SMOKE_yes', 'SCC_yes', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_Transportation', 'MTRANS_Walking']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# Fit the preprocessor on the training data and transform both train and test\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "num_feature_names = num_cols\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
    "feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "print(f\"Training set after preprocessing: {X_train_processed.shape}\")\n",
    "print(f\"Test set after preprocessing: {X_test_processed.shape}\")\n",
    "\n",
    "# Convert to DataFrames for easier saving\n",
    "X_train_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "\n",
    "# Save the preprocessor pipeline for future use\n",
    "pickle.dump(preprocessor, open('../models/preprocessor.pkl', 'wb'))\n",
    "print(\"Preprocessor pipeline saved to '../models/preprocessor.pkl'\")\n",
    "\n",
    "# Save the feature columns for future reference\n",
    "feature_columns = {\n",
    "    'categorical': cat_cols,\n",
    "    'numerical': num_cols,\n",
    "    'encoded': feature_names\n",
    "}\n",
    "pickle.dump(feature_columns, open('../models/feature_columns.pkl', 'wb'))\n",
    "print(\"Feature column names saved to '../models/feature_columns.pkl'\")\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: ../data/processed/train_features.csv\n",
      "Data saved to: ../data/processed/train_labels.csv\n",
      "Data saved to: ../data/processed/test_features.csv\n",
      "Data saved to: ../data/processed/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save train/test data\n",
    "save_dir = '../data/processed/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "train_features_path = os.path.join(save_dir, \"train_features.csv\")\n",
    "train_labels_path = os.path.join(save_dir, \"train_labels.csv\")\n",
    "test_features_path = os.path.join(save_dir, \"test_features.csv\")\n",
    "test_labels_path = os.path.join(save_dir, \"test_labels.csv\")\n",
    "\n",
    "X_train_df.to_csv(train_features_path, index=False)\n",
    "print(f\"Data saved to: {train_features_path}\")\n",
    "\n",
    "pd.DataFrame(y_train, columns=['target']).to_csv(train_labels_path, index=False)\n",
    "print(f\"Data saved to: {train_labels_path}\")\n",
    "\n",
    "X_test_df.to_csv(test_features_path, index=False)\n",
    "print(f\"Data saved to: {test_features_path}\")\n",
    "\n",
    "pd.DataFrame(y_test, columns=['target']).to_csv(test_labels_path, index=False)\n",
    "print(f\"Data saved to: {test_labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
